%\input{preamble1}
%\usepackage{wallpaper}                                          % 使用浮水印
%\CenterWallPaper{0.6}{images/ntpu.eps}                           % 浮水印圖檔
%\begin{document}
%\fontsize{12}{22pt}\selectfont
\cleardoublepage
\thispagestyle{empty}
\setlength{\parindent}{2em}
\chapter{文獻回顧}

  	Frank與Hall（2001）提出一種在分類模型上事先處理次序型資料的方法，將k個目標變數類別轉換為一系列k-1次的二分類問題，並使用條件機率的方式考慮預測該類別的機率，如$P(Y > Cool|X)$、$P(Y > Mild|X)$與$P(Y = Hot|X) = P(Y > Cool|X) - P(Y > Mild|X)$，這使得一般分類算法能夠包含到次序資料本身的特性，最後透過該方法與決策樹的結合表現優於分類模型的樸素貝葉斯(Naïve Bayes)。
  	
  	
	 Cardoso與Pinto da Costa（2007）提出使用數據複製方法(Data Replication Method)將次序型資料問題轉換為二分類問題來處理，該方法在k個目標變數類別問題時做了k-1次二分類預測，每次分類後會給予兩邊所對應的權重，第一次分類會對於$\{C_1\}$與$\{C_2, C_3\}$進行二分類預測並給予兩邊權重，第二次分類針對$\{C_1, C_2\}$與$\{C_3, C_4\}$進行二分類預測並給予兩邊權重，以此概念將k-1次分類做完並依據被給予的權重做出最後的分類，文獻中提到其研究著重於機器學習方法的應用，特別是神經網絡(Neural Network)和支持向量機(SVM)在次序資料分類問題上的應用，且該方法在最後資料實證優於傳統分類問題所用的支持向量機模型(SVM)。Vargas等（2020）提出了一種用於順序回歸的深層卷積神經網絡模型(Deep Convolutional Neural Network)，在神經網絡的輸出層考慮Cumulative link models不同的鏈結函數。
	 
	 上述了解到對於次序型資料的問題，現今機器學習的方法遇上多分類的問題通常都是假設預測變數為名目型資料，即沒有考慮到目標變數本身大小順序的關係，次序型資料的預測方法還是沒有受到太大的重視，而在提出針對次序型資料的處理方法或是在模型預測時將分類問題做為次序問題來考慮，其表現會優於一般的分類模型，代表考慮正確的資料本質有助於最後的模型預測。
	 
	 在文字資料的部分，因文字是無法直接一個字一個字去代入模型的，不管是在中文或英文文字上我們都會先將文字轉為向量，以一連串的向量代表一段文字， Liu（2020）與Liu等（2019）分別提到在做文本分類的命題時使用CBOW法與Skip - gram法能得捕捉到文本的局部特徵，在做詞嵌入(Word Embedding)時使用這兩種方法能得到良好的結果，而Liu等（2019）更是提出一種基於Skip - gram法的循環神經網絡(Recurrent Neural Network)將文字轉換為向量時獲得更準確的信息；Jing等（2002）則是以傳統TF-IDF法做為處理文字的方法，並以基於TF-IDF的特徵選取法對文字預處理做出改善，而後做為文字的詞嵌入，由上述我們可以知道在文字詞嵌入上有非常多種作法，且對於文字預處理的部分是會顯著的影響最終成效。
	 
	 Elbagir與Yang（2019）和Dandannavar與Jain（2016）對Twitter上的文字評論做情感分析，兩者分別以將目標變數視為五類與三類，分別為非常正向、正向、中立、負面、非常負面與正面、中立、負面這類型的次序型資料去做預測，而兩篇研究皆使用機器學習的方法去做預測，如支持向量回歸(SVR)、決策樹(Decision Tree)和隨機森林(Random Forest)等，前者作者以提出的推文極性分數去定義一則留言的五個等級，再去做預測；後者則是強調在文字特徵提取的部分，包含詞性標註、意見詞、推特的特定功能與否定詞等，上述皆顯示出文字的處理與將次序資料本身特性一併考慮進去對預測的重要性，尤其在網友和客戶留言的平台上更是容易見到此類型的資料。




