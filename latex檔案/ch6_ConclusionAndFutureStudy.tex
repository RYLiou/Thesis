%\input{preamble1}
%\usepackage{wallpaper}                                          % 使用浮水印
%\CenterWallPaper{0.6}{images/ntpu.eps}                           % 浮水印圖檔
%\begin{document}
\fontsize{12}{22pt}\selectfont
\cleardoublepage
\thispagestyle{empty}
\setlength{\parindent}{2em}
\chapter{研究結論與建議}

	本章節將會對實驗過程與實驗結果做出總結，實驗過程依序包含對數值與類別型資料、模擬資料與中英文文字資料，最後將給出研究建議。
	
\section{研究結論}

	首先，在三種次序型分類模型Cumulative Logit Model、Continuation-Ratio Logit Model、Adjacent-Category Logit Model與兩種名目型分類模型Naïve Bayes、多元邏輯斯模型，共五種模型之下，我們預測13組目標變數為次序型的數值與類別型態資料，發現名目型分類模型與次序型分類模型的表現不分軒輊，名目型分類模型以多元邏輯斯模型表現最好，次序型分類模型以Cumulative Logit Model最好，而Naïve Bayes在所有資料集中都表現不好，名目型與次序型分類模型表現不分上下的原因可能在於雖然資料的目標變數定義上為次序型，但資料本身並沒有次序型分類模型的比例賠率假設(Proportional Odds Assumption)。透過比例賠率假設檢定，我們發現這13組資料集中。較多變數符合此假設的資料集，使用次序型分類模型中有較好的成效。
	
	過去傳統統計模型強調「解釋能力」（配適能力），若符合前提假設可以預期模型有良好的解釋能力，但較無探討預測能力，因此在5.2章我們使用統計模擬去驗證是否符合前提假設之下的資料在次序型分類模型同樣會有較好的預測能力，結果發現確實這十組模擬資料在次序型分類模型上的成效大多優於名目型分類模型，唯二在名目型分類模型上表現較好的資料集於三種衡量指標上皆與次序型分類模型差距非常小。由上述可以知道，即使資料本身定義為次序型資料，但若其資料樣態並不滿足比例賠率假設，使用次序型分類模型未必獲得較佳預測結果。反之，若資料滿足該假設，則使用次序型分類模型通常有較佳表現。
	
	因現實中資料經常存在資料不平衡的情況，在本研究中也有對此做討論，分為A、B兩種情況，分別為未重抽樣資料建模與低採樣重抽樣資料建模，結果發現不論是在次序型分類模型或名目型分類模型時，皆在資料未經重抽樣之下建模有著較好的預測能力，原因可能在於重抽樣意味著訓練資料的減少，即使重抽樣後的資料筆數仍然具有5000筆以上的訓練資料集，同樣也較難配適出一個更合適的模型。

	應用於文字的部分不論是在中文或英文評論上，詞嵌入的部分CBOW法與Skip-gram法表現最佳，其次是wiki法，最後則是TF-IDF法，由此我們猜測CBOW法與Skip-gram法因考量到當前文本前後文的關聯性，所以轉換為詞向量後的資訊相較其他方法更為貼近文字本身所傳達的意思，且從參數W得知考量到更多前後文確實會提升預測能力。然而這兩種詞向量訓練方法耗時，若能直接使用網路上別人訓練好的wiki法較為省時且也有不差的預測結果，而維度(D)則是在100到150之間有著最佳結果，維度選取上可以在對於文本有更多了解後做文字特徵處理以選取合邏輯下的最佳維度。
	
	中文評論使用次序型分類模型有著較好的預測結果，英文評論使用多元邏輯斯模型有著較好的預測結果，Naïve Bayes則是皆表現最差，過去國外自然語言處理領域中，大多使用多元邏輯斯模型搭配詞嵌入來做預測，本研究發現在中文文字上使用次序型分類模型相較名目型分類模型有著較好的結果，中文與英文本身語句邏輯就不同，或許未來可朝向這部分更深入探究其原因。
	
\newpage

\section{研究建議}

	比例賠率假設是較為嚴格的檢定，變數與資料量大時容易拒絕，在文字使用詞嵌入法轉為詞向量後的維度通常也較高，訓練模型在高維度特徵時容易產生過擬合(Overfitting)的問題，若單純把詞向量中某幾個變數移除可能會影響詞向量本身表達的意思，在已知次序型分佈的資料使用對應的模型時會有較好結果之下，未來可在詞向量特徵選取，或使用正規化(regulariztion)以避免過擬合等議題上做更多的研究。
	
	本研究中使用的多元邏輯斯模型取自nnet套件，在維度為200以上無法執行，未來可嘗試其他套件以應用於更多情況；本研究中使用的Naïve Bayes取自e1071套件，在本研究中的表現相較其餘模型皆較差，或許因為資料集不滿足Naïve Bayes的變數獨立假設，此議題可於未來加以探討。
	
	本研究中重抽樣方法使用最為常見的過採樣(Over Sampling)與欠採樣(Undersampling)，而此方法得到較差的預測結果，未來可考量其他處理不平衡資料的方法來改進資料不平衡的問題，重抽樣方法如4.1.1章節所述。
	
	本研究使用MSE做為參考預測與實際結果等級差異的指標，MSE算法是$l2$正則化，會將預測差距較大的給予更大的懲罰項，未來可使用MAE，也就是$l1$正則化做為衡量指標。



%\end{document}


